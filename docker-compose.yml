services:
  # 1. The Data Warehouse
  warehouse:
    image: postgres:15
    container_name: metrofleet_warehouse
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - pg_data:/var/lib/postgresql/data

  # 2. The Orchestrator (Dagster UI & Daemon)
  # We will build this container based on your python requirements

  orchestrator:
    build:
      context: . # The build context is the root of the repo
      dockerfile: infra/docker/Dockerfile.dagster # Path to the file we just created
    container_name: metrofleet_orchestrator
    environment:
      POSTGRES_HOST: warehouse
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      # MLflow tracking endpoint for training code
      MLFLOW_TRACKING_URI: http://mlflow:5000
      # Where the training script should write the production model file.
      # This path is inside the mounted `./workspaces/python` directory so it
      # will be persisted on the host and accessible to other services.
      PROD_MODEL_PATH: /opt/dagster/app/data/models/price_model_prod.pkl
      # This ensures files are saved to the mounted volume, not inside the container's temp layer
      DATA_ROOT: "/opt/dagster/app/data"
      PYTHONPATH: "/opt/dagster/app/workspaces/python/pipelines"
    volumes:
      - ./workspaces/python:/opt/dagster/app/workspaces/python # Live code reloading for Python
      - ./workspaces/rust:/opt/dagster/app/workspaces/rust # Access to Rust source
      - ./data:/opt/dagster/app/data # Shared data folder
    ports:
      - "3000:3000"
    depends_on:
      - warehouse

  dashboard:
    build:
      context: .
      dockerfile: infra/docker/Dockerfile.dashboard
    container_name: metrofleet_dashboard
    environment:
      POSTGRES_HOST: warehouse
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      # Let dashboard know where the production model will be written
      PROD_MODEL_PATH: /opt/dashboard/app/data/models/price_model_prod.pkl
    volumes:
      # Mount the code for live editing
      - ./workspaces/python/apps/admin_dashboard:/opt/dashboard/app/apps/admin_dashboard
      # Mount the models directory so the dashboard/fastapi can load the model
      - ./data:/opt/dashboard/app/data
    ports:
      - "8501:8501"
    depends_on:
      - warehouse

  notebook:
    build:
      context: .
      dockerfile: infra/docker/Dockerfile.notebook
    container_name: metrofleet_notebook
    environment:
      POSTGRES_HOST: warehouse
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      # Make the production model path available in the notebook environment
      PROD_MODEL_PATH: /app/data/models/price_model_prod.pkl
    volumes:
      - ./workspaces/python/analytics:/app/analytics # Mount the analytics folder
      - ./data:/app/data # Mount data for saving models

    ports:
      - "8888:8888"
    # Overwrite the CMD to start Jupyter instead of Streamlit
    command: [ "jupyter", "lab", "--ip=0.0.0.0", "--allow-root", "--no-browser", "--notebook-dir=/app/analytics" ]
    depends_on:
      - warehouse

  mlflow:
    build:
      context: .
      dockerfile: infra/docker/Dockerfile.mlflow
    container_name: metrofleet_mlflow
    environment:
      # We still need these for the DB connection and Artifact storage
      MLFLOW_BACKEND_STORE_URI: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@warehouse:5432/${POSTGRES_DB}
      MLFLOW_DEFAULT_ARTIFACT_ROOT: /app/data/mlflow_artifacts
      # Note: MLFLOW_SERVER_HOST is now in the Dockerfile, so we don't strictly need it here,
      # but leaving it doesn't hurt. Also expose PROD_MODEL_PATH for consistency (optional).
      PROD_MODEL_PATH: /app/data/models/price_model_prod.pkl
    volumes:
      - ./data:/app/data
    ports:
      - "5000:5000"
    depends_on:
      - warehouse

  api:
    build:
      context: .
      dockerfile: infra/docker/Dockerfile.api
    container_name: metrofleet_api
    volumes:
      # Mount the data folder so it can read the .pkl file
      - ./data:/app/data
      # Mount code for hot-reloading during dev
      - ./workspaces/python/apps/api_gateway:/app
    ports:
      - "8000:8000"
    environment:
      API_KEY: ${METROFLEET_API_KEY:-dev-secret-key}
    # Overwrite command for hot-reloading
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload
    # Fix the Python path so uvicorn finds 'main.py' if mounted differently, 
    # but strictly speaking, the Dockerfile COPYs main.py to /app, so default is fine.
    # However, if using the volume mount above, we should point to it:
    working_dir: /app

  web:
    build:
      context: .
      dockerfile: infra/docker/Dockerfile.web
    container_name: metrofleet_web
    environment:
      METROFLEET_API_URL: http://api:8000
      METROFLEET_API_KEY: ${METROFLEET_API_KEY:-dev-secret-key}
      METROHAIL_DB_URI: ${METROHAIL_DB_URI}
    ports:
      - "3001:3000"
    depends_on:
      - api

  analyst:
    build:
      context: .
      dockerfile: infra/docker/Dockerfile.analyst
    container_name: metrofleet_analyst
    environment:
      # Point the analyst app to the same warehouse used by other services
      POSTGRES_HOST: warehouse
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      # AI provider credentials (do not commit secrets)
      GOOGLE_GENERATIVE_AI_API_KEY: ${GOOGLE_GENERATIVE_AI_API_KEY}
      # Optional: other provider-specific vars (e.g., GOOGLE_PROJECT_ID)
    ports:
      - "3002:3000"
    depends_on:
      - warehouse

volumes:
  pg_data:
